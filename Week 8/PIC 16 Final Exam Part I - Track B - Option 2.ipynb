{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task in this option is create a random Haiku generator program. A Haiku is a poem like:\n",
    "\n",
    "Whitecaps on the bay: <br>\n",
    "A broken signboard banging <br>\n",
    "In the April wind. <br>\n",
    "— Richard Wright, collected in Haiku: This Other World, 1998, copied from <a href = \"https://en.wikipedia.org/wiki/Haiku\">Wikipedia</a>\n",
    "\n",
    "A haiku is defined not by a rhyme pattern, but by the number of syllables in each line. Traditionally, a haiku has three lines: <br>\n",
    "First: Five syllables. <br>\n",
    "Seven in the second line, <br>\n",
    "and Five in the third. <br>\n",
    "— Matt Haberland\n",
    "\n",
    "Your random haiku genarator will generate haikus worthy of literary praise almost surely. Of course, it will generate many, many more bad haikus, like:\n",
    "\n",
    "gnatcatcher julep <br>\n",
    "renewable unite male <br>\n",
    "miscreation loll <br>\n",
    "— Matt Haberland's random haiku generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin, you might need to use the NLTK downloader to get the corpora <tt>cmudict</tt> and <tt>words</tt>. If they are already installed, the following should succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-88e542740c2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not, you need to get them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to give you some help. <tt>cmudict.dict()</tt> returns a Python dictionary in which each key is a word and the corresponding value is a <i>list</i> containing ways of pronouncing the word. When there is more than one pronunciation, the list has more than one element. I suggest you explore some entries in <tt>cmyduct.dict()</tt> to get a better sense of what's going on. Try looking up the pronunciation \"hello\" and \"goodbye\". <i>Don't worry at all if you don't understand how to interpret the pronunciations. I don't. It's irrelevant for this problem. The only point is that each key is a word and the corresponding value is a <i>list</i> containing some representation of ways of pronouncing the word</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = cmudict.dict()\n",
    "# Explore this object.\n",
    "# Suggestion: don't print it all. \n",
    "# That would take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'HH', u'AH0', u'L', u'OW1'], [u'HH', u'EH0', u'L', u'OW1']]\n"
     ]
    }
   ],
   "source": [
    "d.keys()\n",
    "print d[\"hello\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we can write a function that determines the number of syllables in a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nsyl(word):\n",
    "  return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]]\n",
    "# I did not write this. \n",
    "# Tomorrow I'll share the source...\n",
    "# if you ask nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need to understand <i>exactly</i> how the function works, because that would require understanding how the dictionary represents pronunciations. But in short, <tt>nsyl</tt> does some processing on the pronunciations to determine the number of syllables in each pronunciation. Before proceeding, I suggest you try it out on \"hello\", \"goodbye\", and maybe some other common words to get a sense of how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsyl(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Create a dictionary <tt>d2</tt> in which each key is an integer and the corresponding value is a list of all words with that many syllables. <i>For words with multiple pronunciations, consider only the first pronunciation. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-4b40f62cb0e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnsyl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0md2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnsyl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "d2 = {}\n",
    "words = []\n",
    "keys = sorted(d.keys())\n",
    "for i in keys:\n",
    "    if i in words.words():\n",
    "        if not nsyl(i)[0] in d2:\n",
    "            d2[nsyl(i)[0]] = [i]\n",
    "        else:\n",
    "            (d2[nsyl(i)[0]]).append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) One word in the dictionary contains more syllables than any other. Print this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print max(d2.keys()), d2[max(d2.keys())] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Print the number of words with a given number of syllables like:\n",
    "<pre>\n",
    "0: 4\n",
    "1: 16240\n",
    "2: 56982\n",
    "</pre>\n",
    "etc... <br>\n",
    "Note that there are are some words with zero syllables. That's fine. Not all \"words\" in the dictionary are real English words. We'll revisit this in the very last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in d2.keys():\n",
    "    print i, \":\", len(d2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4) Create a histogram with the title \"Number of Syllables in English Words\" using Plotly (offline). I want you to use the <tt>Histogram</tt> trace, but if you can't figure out how to do that you may use a different type of trace (slight penalty). Whatever you do, the frequency/count of words of a given number of syllables should be represented by a vertical bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "#py.init_notebook_mode()\n",
    "from plotly.graph_objs import Layout, Histogram, Figure, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = []\n",
    "\n",
    "for i in d2.keys():\n",
    "    for j in range(len(d2[i])):\n",
    "        new_x.append(i)\n",
    "trace = Histogram(x = new_x)\n",
    "data = [trace]\n",
    "layout = Layout(title = \"Number of Syllables in English Words\")\n",
    "fig = Figure(data = data, layout = layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Write a function <tt>sylPattern(n)</tt> that returns a list of random integers that sum to <tt>n</tt>. (Later, you will choose for each element of the list a random word with the given number of syllables.) Your function should work for any n > 1. Test it for n = 15. For example:\n",
    "<pre>\n",
    "x = sylPattern(15)\n",
    "print x\n",
    "print sum(x) == 15\n",
    "</pre>\n",
    "should print something like:\n",
    "<pre>\n",
    "[1, 5, 1, 1, 5, 2]\n",
    "True\n",
    "</pre>\n",
    "<i>Hint: You don't need to know any special functions to do this; all you need is basic random number generation capability from the </i><tt>random</tt><i> module. The rest of the algorithm is up to you.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 5, 1, 1, 1]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def sylPattern(n):\n",
    "    numlist = []\n",
    "    k = random.randint(1,n)\n",
    "    numlist.append(k)\n",
    "    remain = n - k\n",
    "    while sum(numlist) < n:\n",
    "        k = random.randint(1, remain)\n",
    "        remain = remain - k\n",
    "        \n",
    "        if remain < 0:\n",
    "            numlist = []\n",
    "        elif remain == 0:\n",
    "            numlist.append(k)\n",
    "            break\n",
    "        numlist.append(k)\n",
    "\n",
    "    return numlist   \n",
    "    \n",
    "x = sylPattern(15)\n",
    "print x\n",
    "print sum(x) == 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Write and test a function <tt>randWord(n)</tt> that returns a random word with <tt>n</tt> syllables. For instance:\n",
    "<pre>\n",
    "print randWord(6)\n",
    "</pre>\n",
    "shows something like:\n",
    "<pre>\n",
    "amiability\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atherosclerosis\n"
     ]
    }
   ],
   "source": [
    "def randWord(n):\n",
    "    randindex = random.randint(1,len(d2[n]))\n",
    "    return d2[n][randindex]\n",
    "print randWord(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Write and test a function <tt>randLine(n)</tt> that returns a line with <tt>n</tt> syllables (separated by spaces). For instance:\n",
    "<pre>\n",
    "randLine(10)\n",
    "</pre>\n",
    "shows something like:\n",
    "<pre>\n",
    "porcupine melodrama gable scot\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " scratch algeo applicability\n"
     ]
    }
   ],
   "source": [
    "def randLine(n):\n",
    "    words = [randWord(i) for i in sylPattern(n)]\n",
    "    wordstr = \"\"\n",
    "    for i in words:\n",
    "         wordstr += \" {}\".format(i)\n",
    "    return wordstr\n",
    "print randLine(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Finally, write and test haiku(). For instance:\n",
    "<pre>\n",
    "print haiku()\n",
    "</pre>\n",
    "should show a haiku formatted like:\n",
    "<pre>\n",
    "psalm degenerate\n",
    "lapsed land mend holl franchiser\n",
    "chia ill pint draft\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " editha blaesing\n",
      " licitra mentions mann theall\n",
      " marietta pih\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def haiku():\n",
    "    wordlist = [randLine(5), randLine(7), randLine(5)]\n",
    "    wordstr = \"\"\n",
    "    for i in wordlist:\n",
    "        wordstr += \"{}\\n\".format(i)\n",
    "    return wordstr\n",
    "print haiku()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) You might not recognize all the words in your haikus. That's partly because <tt>d = cmudict.dict()</tt> contains many proper nouns and some strings that aren't really words, like \"ths\". For the last little bit of credit, go back and make sure that your dictionary <tt>d2</tt> only contains words that are <i>also</i> in <tt>words.words</tt>, which is a list of true English words. Note that if you are not careful, assembling your <tt>d2</tt> with this criterion can take a very long time. If you want these points, your solution should be reasonably efficient. (Assembling <tt>d2</tt> should take no more than a few seconds.) <i>Hint: in general, searching through a list is slow.</i>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
